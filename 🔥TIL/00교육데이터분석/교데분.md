# R Basic
```{r}
a=1
b=2

a+b
```

# 2주차

```{r}
ex1 <- read.csv("/Users/e_o_n_l_a_/Library/Mobile Documents/com~apple~CloudDocs/🤮🤮🤮🤮🤮/교데분/data/ex1.csv", header = T)
colnames(ex1)[1] <- "ID"
head(ex1,10)
```

### 양적 변수와 질적 변수 확인

```{r}
str(ex1)
```

### 범주형 자료의 요약 ; 빈도를 전체 샘플 수인 150으로 나누어서 상대빈도를 구함

```{r}
data <- data.frame(Answer=c("Yes", "SoSo", "No", "Missing"),
                   Freq=c(71,42,28,9))
data$RF <- round(data$Freq/150,3)

head(data)
```

### 원도표

```{r}
# 기본 내장함수 pie 사용
pie(data$RF, labels=paste(data$Answer, data$RF*100,"%"))

library(ggplot2)
ggplot(data, aes(x="", y = RF,fill=Answer))+geom_bar(width = 1,stat="identity")+coord_polar("y") +theme_void()+ geom_text(aes(label=paste0(round(RF*100,1),"%")),position=position_stack(vjust=0.5))
```

### 막대그래프 bar chart

```{r}
barplot(data$Freq, names=data$Answer)
ggplot(data=data, aes(Answer, Freq) ) +  geom_col(fill="blue")
```

### Word Cloud

```{r}
library("wordcloud")
library("tm")
biden.text<-readLines("/Users/e_o_n_l_a_/Library/Mobile Documents/com~apple~CloudDocs/🤮🤮🤮🤮🤮/교데분/data/biden.txt")

# Load the data as a corpus
biden.docs <- Corpus(VectorSource(biden.text))

inspect(biden.docs[1:3])

# Convert the text to lower case
biden.docs <- tm_map(biden.docs, content_transformer(tolower))

# Remove numbers
biden.docs <- tm_map(biden.docs, removeNumbers)

# Remove english common stopwords
biden.docs <- tm_map(biden.docs, removeWords, c("the","and","will","for","are","that",
                                                "but","and","have","with","from","our"))

# Remove punctuations
biden.docs <- tm_map(biden.docs, removePunctuation)

# Eliminate extra white spaces
biden.docs <- tm_map(biden.docs, stripWhitespace)

# 행렬의 형태로 다시 데이터 변환 
biden.dtm <- TermDocumentMatrix(biden.docs)
# as.matrix 이용해 매트릭스 형태로 바꿈
biden.mat <- as.matrix(biden.dtm)
v <- sort(rowSums(biden.mat),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)

# wordcloud() 함수 이용해서 d라는 데이터셋에서의 각 단어별 가중치 반영하여 글씨 크기 다르게 
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 2, scale=c(3,0.5),
          max.words=200, random.order=FALSE, rot.per=0.35,
          colors=brewer.pal(8, "Dark2"))
```

## 연속형 자료의 요약

### 도수분포표

```{r}
# 계급의 수 7 ; 7개의 계급 안에 각각의 자료들이 어느구간에 속하는지를 만들어서 fh라는 변수로 담았다
fh <- cut(ex1$Midterm, breaks = 7, dig.lab=0, right = TRUE, include.lowest = TRUE)
fh

# 도수
y <- table(fh)
y <- data.frame(y)
y

# 상대도수 ; 전체 빈도를 전체 샘플 사이즈로 나누어서 계산해서 y 데이터에 붙이기
y$relFreq <- round(y$Freq/dim(ex1)[1],3)
y
```

### 히스토그램

```{r}
hist(ex1$Midterm, breaks = 20)
hist(ex1$Midterm, breaks = 10)

# ggplot histogram ; Midterm 집어넣어서 ggplot() 함수 먼저 설정 > xlab() 함수 이용해서 x축의 label 쓰고 > 히스토그램 함수 이용해서 히스토그램 그리라는 명령어 넣음 > bin의 갯수는 10개로 지정 
ggplot(ex1, aes(x = Midterm)) + xlab("Midterm") + geom_histogram() + stat_bin(bins=10)
```

### 도수다각형 ; 히스토그램을 hist() 함수 이용해서 그린 후 위에 lines() 함수 이용해서 도수다각형 겹쳐 그림

```{r}
h <- hist(ex1$Midterm, breaks = 10)
lines(h$mids, h$counts)
```

### 밀도함수 추정 ; 중간고사 성적에 대한 ggplot() 함수 만들기 > density() 함수 이용해서 밀도함수 추정하여 시각화 > 그룹별로 밀도함수 추정해서 시각화 하고 싶다면 그룹 변수 지정해서 그리기 (세번째는 성별, 네번째는 혈액형별로 그룹화)

```{r}
midterm.plot <- ggplot(ex1, aes(x = Midterm)) + xlab("Midterm")
midterm.plot + geom_density()
midterm.plot + geom_density(aes(fill = as.factor(Gender)), alpha = 0.5)
midterm.plot + geom_density(aes(fill = as.factor(Btype)), alpha = 0.5)
```

### 줄기잎그림

```{r}
stem(ex1$Midterm)
```

### 상자그림

```{r}
# 성별에 따른 중간고사 성적의 상자그림 ; 성별에 따라 따로 그리기 위해 뒷부분에 Gender 변수 집어넣어 그림 
boxplot(ex1$Midterm~ex1$Gender)

# use ggplot
ggplot(ex1, aes(x = as.factor(Gender), y = Midterm)) + geom_boxplot()
# 혈액형별
ggplot(ex1, aes(x = as.factor(Btype), y = Midterm)) + geom_boxplot()
```

### 자료의 요약 : 수치

```{r}
mean(ex1$Midterm) #표본평균
median(ex1$Midterm) #중앙값 

# summary() ; 최솟값, 최댓값, 평균, 중앙값, Q1, Q3
summary(ex1$Midterm)
quantile(ex1$Midterm, probs=0.25) # Q1
quantile(ex1$Midterm, probs=0.50) # Q2
quantile(ex1$Midterm, probs=0.75) # Q3

# 더 다양한 수치적 요약 값
library(pastecs)
stat.desc(ex1$Midterm)
```

## 두 변수의 요약

### 분할표

```{r}
# 성별과 혈액형 요약
table(ex1$Gender, ex1$Btype)

# 상대도수
t <- table(ex1$Gender, ex1$Btype)
round(prop.table(t),3)
```

### 산점도

```{r}
# plot(y축에 놓일 변수 ~ x축에 놓일 변수)
plot(Midterm~Final, data=ex1)
```

### 상관계수

```{r}
cor(ex1$Midterm, ex1$Final) # 0.7 정도로 아주 높은 양의 상관관계가 있음을 확인 가능
```

### 상관계수 행렬 correlation matrix

```{r}
sat <- read.csv("/Users/e_o_n_l_a_/Library/Mobile Documents/com~apple~CloudDocs/🤮🤮🤮🤮🤮/교데분/data/SATscore.csv", header = T)
head(sat)

# id 제거
sat <- sat[,-1]
head(sat)

cor(sat)

library(corrplot)

corrplot(cor(sat))
```

# 3주차

### 고전적 확률

- 한 반에 있는 25명의 학생 중 8명이 왼손잡이라고 할 때, 이 중 한 명을 임의로 선택할 때 이 학생이 왼손잡이일 확률은?
- choose ; combination 함수 nCr

```{r}
choose(8,1)/choose(25,1)
```

### 주사위를 던졌을 때 짝수가 나올 확률

```{r}
library(sets)
# 표본공간
S = set(1,2,3,4,5,6)
# 짝수인 사건
A = set(2,4,6)
# 짝수가 나타날 확률 ; 원소의 갯수를 세는 함수 length()
P_A = length(A)/length(S)
P_A
```

#### 조건부 확률 ; 주사위를 던졌을 때 짝수가 나왔다는 조건 하에 3의 배수가 나올 확률은?

```{r}
B = set(3,6)
AandB = set_intersection(A,B) # 교집합 만드는 함수 set_intersection()
A
B
AandB
P_BgivenA = length(AandB)/length(A)
P_BgivenA
```

### 통계적 확률 실험

```{r}
# 동전을 n번 던졌을 때 앞면, 뒷면이 나오는 횟수
# H문자와 T문자를 랜덤하게 n개 추출하는 코드
n<-10
coin<-sample(c("H", "T"), n, replace = TRUE, prob = c(1/2,1/2)) # 확률(prob)을 정확히 2분의 1로 설정
head(coin)
table(coin)
sum(coin == "H")/n # 앞면이 나오는 확률
```

### Bayes Rule

- 어느 동에는 고등학교 A1, A2, A3가 있으며 이 동의 전체 학생 수 중 각각 30%, 50%, 20%를 차지한다. 학교 A1, A2, A3의 학생 학업 중단 비율은 각각 2%, 1%, 5%이다.

```{r}
# c() ; 열 column 생성 명령어
prior <- c(0.3, 0.5, 0.2) # P(A1), P(A2), P(A3)
cond <- c(0.02, 0.01, 0.05) # P(B|Ak)
tot <- prior*cond
tot
sum(tot) # P(B)
post <- tot/sum(tot) # P(Ak|B)
post
```

### 확률변수의 기대값, 분산

```{r}
x <- c(0, 1, 2, 3, 4)
pr.x <- c(0.1, 0.2, 0.4, 0.2, 0.1)
# 기대값
EX <- sum(x*pr.x)
EX
#분산 (간편계산식)
var.x <- sum((x^2)*pr.x)-EX^2
var.x
#표준편차
sd.x <- sqrt(var.x)
sd.x
```